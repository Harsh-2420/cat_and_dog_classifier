{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2              \n",
    "import numpy as np      \n",
    "import os                 \n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = \"/Users/harshjhunjhunwala/desktop/projects/deep_learning_cost_function/dataset/train\"\n",
    "test_dir = \"/Users/harshjhunjhunwala/desktop/projects/deep_learning_cost_function/dataset/test\"\n",
    "img_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labelling the cat and dog images separately\n",
    "\n",
    "def label_img(img):\n",
    "    temp_label = img.split('.')[-3]\n",
    "    if temp_label == 'cat':\n",
    "        return [1, 0]\n",
    "    elif temp_label == 'dog':\n",
    "        return [0, 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25000/25000 [01:56<00:00, 213.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# Create training_set\n",
    "\n",
    "def create_train_data():\n",
    "    training_data = []\n",
    "    for img in tqdm(os.listdir(train_dir)):\n",
    "        label = label_img(img)\n",
    "        path = os.path.join(train_dir, img)\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (img_size,img_size))\n",
    "        training_data.append([np.array(img),np.array(label)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy', training_data)\n",
    "    return training_data\n",
    "\n",
    "train_data = create_train_data()\n",
    "\n",
    "train_set_x_orig = []\n",
    "for img in train_data:\n",
    "    train_set_x_orig.append(img[0])\n",
    "\n",
    "train_set_y = []\n",
    "for img in train_data:\n",
    "    train_set_y.append(img[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1377/12500 [00:06<00:56, 198.46it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-6d20cb0829d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtesting_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mtest_set_x_orig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-6d20cb0829d9>\u001b[0m in \u001b[0;36mprocess_test_data\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dir\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mimg_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIMREAD_GRAYSCALE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mimg_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mtesting_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Creating test_set\n",
    "\n",
    "def process_test_data():\n",
    "    testing_data = []\n",
    "    for img in tqdm(os.listdir(test_dir)):\n",
    "        path = os.path.join(test_dir,img)\n",
    "        img_num = img.split('.')[0]\n",
    "        img = cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.resize(img, (img_size,img_size))\n",
    "        testing_data.append([np.array(img), img_num])\n",
    "        \n",
    "    shuffle(testing_data)\n",
    "    np.save('test_data.npy', testing_data)\n",
    "    return testing_data\n",
    "\n",
    "test_data = process_test_data()\n",
    "\n",
    "test_set_x_orig = []\n",
    "for img in test_data:\n",
    "    test_set_x_orig.append(img[0])\n",
    "\n",
    "test_set_y = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Loading in the data (cat and dog images in .jpg)\n",
    "# def load_dataset():\n",
    "#     with h5py.File('datasets/train_catvnoncat.h5', \"r\") as train_dataset:\n",
    "#         train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:])\n",
    "#         train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:])\n",
    "\n",
    "#     with h5py.File('datasets/test_catvnoncat.h5', \"r\") as test_dataset:\n",
    "#         test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:])\n",
    "#         test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:])\n",
    "#         classes = np.array(test_dataset[\"list_classes\"][:])\n",
    "\n",
    "#     train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "#     test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "\n",
    "#     return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes\n",
    "\n",
    "# train_set_x_orig, train_set_y, test_set_x_orig, test_set_y, classes = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the helper functions\n",
    "# sigmoid function:\n",
    "\n",
    "def sigmoid(x):\n",
    "    s = 1/ (1 + np.exp(-x))\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising parameters\n",
    "# Creating vector with zeroes and initialising w and b param\n",
    "\n",
    "def initialise(v):\n",
    "    \"\"\"\n",
    "    Create a vector of np.shape() = (v, 1) and initialise b to 0\n",
    "    \"\"\"\n",
    "    w = np.zeros((v, 1))\n",
    "    b = 0 \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward and Backward Propogation\n",
    "\n",
    "def propogation(w, b, X, Y):\n",
    "    \"\"\"\n",
    "    Implement cost function and its gradient for the propogation\n",
    "    \"\"\"\n",
    "    m = X.shape[1] # m is used to average out the cost function and so it is the total number of columns in X\n",
    "    \n",
    "    # Forward Propogation\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    cost = (-1 / m) * np.sum(Y * np.log(A) + (1 - Y)* np.log(1 - A)) \n",
    "    \n",
    "    # Backward Propogation\n",
    "    dw = 1/m * np.dot(X, (A - Y).T)\n",
    "    db = i/m * np.sum(A - Y)\n",
    "    \n",
    "    grads = {\"dw\": dw, \"db\": db}\n",
    "    \n",
    "    return grads, cost\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimization \n",
    "\n",
    "def optimize(w, b, X, Y, num_iter, learning_rate, print_cost):\n",
    "    costs = []\n",
    "    for i in range(num_iter):\n",
    "        grads, cost = propogation(w, b, X, Y)\n",
    "        dw = grads['dw']\n",
    "        db = grads['db']\n",
    "        \n",
    "        w = w - learning_rate * dw\n",
    "        b = b - learning_rate * db\n",
    "        \n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        \n",
    "        if print_cost and i % 100 == 0:\n",
    "            print(\"Cost after iteration %i: %f\" % (i, cost))\n",
    "        params = {'w': w, 'b': b}\n",
    "        grads = {\"dw\": dw, \"db\": db}\n",
    "\n",
    "        return params, grads, costs    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the initial prediction model using our new w and b\n",
    "\n",
    "def predict(w, b, X):\n",
    "    m = X.shape[1]\n",
    "    Y_prediction = np.zeros((1, m))\n",
    "    w = w.reshape(X.shape[0], 1)\n",
    "    \n",
    "    # Vector A is to predict the probability\n",
    "    A = sigmoid(np.dot(w.T, X) + b)\n",
    "    \n",
    "    for i in range(A.shape[1]):\n",
    "        Y_prediction[0, i] = 1 if A[0, i] > 0.5 else 0\n",
    "    \n",
    "    return Y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
